



# Fetch System Architecture

이번 챕터에서는 fetch system 의 아키텍처 설계에 관해 소개합니다.



### Microservice Architecture

초기에는 fetch system 의 요구사항을 그렇게 엄격하게 지켜야 한다고 생각하지 않았습니다. 그래서 앞서 소개한 서비스를 하나의 인스턴스에서 모두 구현하고자 하였습니다. 그러나 이는 우아한 방법은 아니었고, 몇가지 눈에 밟히는 문제들이 있었습니다. 기존 아키텍처는 마이크로서비스를 가장한 사실상의 모놀리스(Monolitic Service) 라고 보았고, 더 엄격한 수준의 품질을 만족하기 위해 서비스의 역할을 여러 컴포넌트로 쪼개기 시작했습니다.

기존 fetch system 에서 담당하던 핵심 기능은 다음과 같습니다.
1. 외부 api 를 통해 데이터를 구독
2. trade 데이터를 초, 분 등으로 묶어서 처리
3. kafka 로 실시간 데이터를 전송
4. mongodb 에 과거 데이터를 저장

이를 다음과 같이 인프라로 이전할 수 있습니다.
* kafka streams 는 kafka broker 에서 데이터를 읽어 batch data 를 만들어 다시 kafka broker 에 전송하는 기능을 제공합니다.  이를 중첩으로 적용하면 틱.. 1s, 5s, 1m, 5m 등으로 여러 종류로 가공된 데이터를 얻을 수 있습니다.
* kafka connect 는 kafka broker 의 source 에서 데이터를 읽어 mongoDB 에 저장하는 기능을 제공합니다.
* 이렇게 많은 기능을 인프라로 이전하면 application 은 외부 api 를 구독하여 kafka 로 전송하는 기능만 담당할 수 있습니다.

이렇게 기능을 인프라로 이전하는 것은 도메인을 단순화하는 한편 운영 복잡도는 증가시키는 일종의 트레이드 오프입니다. 어플리케이션을 가볍게 만드는 것은 특별히 다음과 같은 장점들을 가져다줍니다.

1. 장애 대응 능력을 높여주고, 어플리케이션의 부담을 줄여 장애 발생 가능성을 낮춥니다.
kafka 는 모든 과정에서 데이터를 statefull 하게 관리하기 때문에 문제가 발생하더라도 데이터의 유실 가능성을 낮춰줍니다. 또한 어플리케이션이 가벼워졌기 때문에 장애의 발생 가능성이 낮아집니다. 만약 어플리케이션에서 부하 등으로 인해 장애가 발생하더라도 이외의 카프카 인프라가 담당하는 부분은 부분적으로 정상적으로 동작할 수 있습니다.

2. worker 을 더 자유롭게 관리할 수 있습니다.
worker 의 역할이 축소되었기 때문에 다음에 소개할 master - worker 패턴을 도입할 수 있습니다. 이는 서비스의 디테일한 부분에서의 퀄리티를 높일 수 있는 중요한 패턴입니다.

저희는 특별히 두 번째 장점을 크게 평가하였고, 하나의 단일 어플리케이션의 역할을 worker, master, kafka part 로 분리하였습니다.



### Master Worker Pattern

master worker pattern 은 대표적으로 쿠버네티스가 사용하는 패턴으로, worker 이 실제 태스크를 처리하고, master 은 worker 을 관리합니다. 저희 서비스에도 이를 도입하여 데이터를 받아오는 worker 을 두고 이를 master 이 관리하는 구조를 적용하였습니다. 이와 같은 패턴 도입으로 인해 아래와 같은 부분들에서 개선을 이루었습니다.

1. scailing-out 이 가능합니다.
여러 거래소에서는 매초 수천 건의 거래가 발생하고 있고 fetch system 은 그러한 데이터를 전부 구독합니다. 따라서 fetch system 에 작용하는 트래픽 부하는 무시할 수 없는 수준입니다. worker 을 여러개 띄워 각 worker 이 각각의 상품들을 구독하도록 하고, 서비스가 확장될 때마다 worker 을 더 띄운다면 이러한 부하에 잘 대응할 수 있습니다.

2. replica worker 을 띄워 장애에 대응할 수 있습니다.
fetch system 이 구독하는 모든 데이터가 다 중요하지만, 그 중에서도 어떤 종류는 절대로 유실되어서는 안되는 것이 있습니다. 그러나 클라우드 인프라에서는 서버 부하 네트워크 문제를 비롯 예측할 수 없는 요인들로 인한 장애 상황을 항상 염두에 두어야 합니다. 어떤 running worker 와 동일한 데이터를 구독하는 replica worker 을 함께 띄워 언제든지 running worker 의 장애 상황에 이를 대체할 수 있도록 할 수 있습니다.

3. 무중단 배포가 가능합니다.
worker 은 외부 API 에 연결하여 데이터를 받아옵니다. 외부 서버가 fetch system 에 요청을 보내는 방식이 아니기 때문에 로드밸런싱이 불가능하고 데이터의 중복이 발생합니다. 이로 인해 기존의 서비스에서는 kubernetes 에서 제공하는 rollout 기능만을 사용하여서는 무중단 배포를 할 수 없습니다. 그러나 어떤 종류의 상품은 24간 내내 거래되어 항상 시세를 받아와야 하기 때문에 어플리케이션을 업데이트 해야 하는 상황에서 치명적일 수 있습니다. 2번에서 소개한 방법을 조금 응용하면 무중단 배포를 달성할 수 있습니다.



### ETCD

또한 분산 환경에서 가용성을 높이기 위해 master 과 worker system 전체가 공유하는 메타데이터 저장소로 ETCD 를 사용하였습니다. etcd 데이터의 안전성을 가장 중요한 목적으로 하는 준수한 속도의 key-value store 입니다. master 을 stateless 하게 관리하여 역할을 완전히 etcd 에 위임하였습니다.

특히 이번 프로젝트에서는 etcd 에서는 특별하게 prefix query 를 제공하는 점을 활용해 객체 형태의 데이터를 직렬화하여 etcd에 간편하게 저장하고 불러올 수 있는 라이브러리를 만들어 사용하였습니다.

